{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, cv2, math, csv, tqdm, random, keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import util \n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras import backend as k\n",
    "from keras import applications, optimizers, losses, layers\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras import layers ,losses\n",
    "from keras.layers import Dropout, Input, Flatten, Dense, GlobalAveragePooling2D, Activation, LSTM, SeparableConv2D, TimeDistributed, GRU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers.convolutional import Conv2D\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_list_load(seq, root):\n",
    "    img_path_total = []\n",
    "    lab_path_total = []\n",
    "    for seq_ch in seq:\n",
    "        img_dir = os.path.join(root, 'sequences', seq_ch,'image_2')\n",
    "        seq_pose = seq_ch + '.txt'\n",
    "        lab_dir = os.path.join(root, 'poses', seq_pose)\n",
    "        lab_list = util.load_dof6_labels(lab_dir)\n",
    "        lab_dir = os.path.join(root, 'poses', seq_pose)\n",
    "        paths = sorted(glob.glob(img_dir+'/*.png'))\n",
    "\n",
    "        for i in tqdm.tqdm(paths):\n",
    "            img_time = [[paths[i], paths[i+1], paths[i+2], \n",
    "                         paths[i+3], paths[i+4], paths[i+5], \n",
    "                         paths[i+6], paths[i+7], paths[i+8], \n",
    "                         paths[i+9], paths[i+10]] \n",
    "                        for i in range(len(paths)-10)]\n",
    "        img_path_total = img_path_total + img_time\n",
    "        lab_path_total = lab_path_total + lab_list[9:]\n",
    "    print(len(img_path_total), len(lab_path_total))\n",
    "    return img_path_total, lab_path_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(total_img, total_lab, batch):\n",
    "    total = []        \n",
    "    while 1:\n",
    "        idx = list(range(0,len(total_img)))\n",
    "        idx_batch = random.sample(idx,batch)\n",
    "        \n",
    "        bat_img = []\n",
    "        bat_lab = []\n",
    "        \n",
    "        for i in idx_batch:\n",
    "            tmp_img = []\n",
    "            for j in range(10):\n",
    "                img = cv2.resize(np.concatenate((Image.open(total_img[i][j]),Image.open(total_img[i][j+1])),axis = 2),(512,384))/255.\n",
    "                tmp_img.append(img)\n",
    "            lab = total_lab[i]\n",
    "            bat_img.append(np.array(tmp_img))\n",
    "            bat_lab.append(lab) \n",
    "        yield np.array(bat_img), [np.array(bat_lab)[:,:3],np.array(bat_lab)[:,3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(total_img, total_lab, batch):\n",
    "    total = []\n",
    "    idx_batch = 0        \n",
    "    while 1:\n",
    "        bat_img = []\n",
    "        bat_lab = []\n",
    "        tmp_img = []       \n",
    "        for j in range(10):\n",
    "            img = cv2.resize(np.concatenate((Image.open(total_img[idx_batch][j]),Image.open(total_img[idx_batch][j+1])),axis = 2),(512,384))/255.\n",
    "            tmp_img.append(img)\n",
    "        lab = total_lab[idx_batch]\n",
    "        bat_img.append(np.array(tmp_img))\n",
    "        bat_lab.append(lab) \n",
    "        print(idx_batch)\n",
    "        idx_batch = idx_batch + 1\n",
    "        yield np.array(bat_img), [np.array(bat_lab)[:,:3],np.array(bat_lab)[:,3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 16\n",
    "train_seq = ['00','01','02','03','04','05','06','07','08']\n",
    "train_root= '/data1/Kitti/odometry/'\n",
    "train_list, train_lab = data_list_load(train_seq, train_root)\n",
    "train = data_generator(train_list, train_lab, batch)\n",
    "\n",
    "val_seq = ['09']\n",
    "val_root= '/data1/Kitti/odometry/'\n",
    "val_list, val_lab = data_list_load(val_seq, val_root)\n",
    "val = data_generator(val_list, val_lab, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('save_lstm/20190521_deepvo_gap_lstm_step_20000_epoch4_00000001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    model.layers[i].trainable = False\n",
    "model.compile(optimizer='adam', loss=['mse','mse'],loss_weights=[100,1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = keras.callbacks.ModelCheckpoint('save_lstm/20190521_deepvo_gap_lstm_step_20000_epoch5_{epoch:08d}.h5', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train, steps_per_epoch=2500, epochs=5, callbacks=[mc],\n",
    "                           validation_data= val, validation_steps= 5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = 1\n",
    "test_seq = ['10']\n",
    "test_root= '/data1/Kitti/odometry/'\n",
    "test_list, test_lab = data_list_load(test_seq, test_root)\n",
    "test = test_generator(test_list, test_lab, batch)\n",
    "predic = []\n",
    "labels = []\n",
    "for i in range(1000):\n",
    "    test_img, test_lab = next(test)\n",
    "    labels.append(np.reshape(np.concatenate((np.array(test_lab)[0],np.array(test_lab)[1]),axis=1),(1,6))[-1,:])\n",
    "    predic_tmp = model.predict(test_img)\n",
    "    predic.append(np.reshape(np.concatenate((np.array(predic_tmp)[0],np.array(predic_tmp)[1]),axis=1),(1,6))[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_np = np.array(predic)\n",
    "labels_np = np.array(labels)\n",
    "path = util.dof6_to_eval_path(predic_np)\n",
    "path_gt = util.dof6_to_eval_path(labels_np)\n",
    "\n",
    "plt.plot(path[0,:],path[2,:],'r')\n",
    "plt.plot(path_gt[0,:],path_gt[2,:],'g')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
